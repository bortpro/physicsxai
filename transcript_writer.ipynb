{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb1db7d-d476-43ac-a07b-6a1efb4d99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "import os\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3f25a9-f419-47fa-9b63-a8fadee78b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(filename):\n",
    "    # Try UTF-8 first (most common encoding for text files)\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except UnicodeDecodeError:\n",
    "        # If UTF-8 fails, try with other common encodings\n",
    "        encodings = ['latin-1', 'cp1252', 'iso-8859-1']\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                with open(filename, 'r', encoding=encoding) as file:\n",
    "                    content = file.read()\n",
    "                print(f\"Successfully read file using {encoding} encoding.\")\n",
    "                return content\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        print(f\"Error: Could not decode file '{filename}' with any common encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not read file '{filename}'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b2467e-2f9a-4fe1-b0dc-79c535063cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_podcast_transcript_claude(system_prompt, input_prompt):\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",  # You can change this to other Claude models as needed like claude-3-opus-20240229 or claude-3-5-sonnet-20241022\n",
    "            max_tokens=1500,\n",
    "            temperature=0.7,\n",
    "            system=system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": input_prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.content[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46c682c-d9b5-4ec0-b08b-8bf5f4c94c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =  \"\"\"\n",
    "You are the a world-class podcast writer, you have worked as a ghost writer for Joe Rogan, Lex Fridman, Ben Shapiro, Tim Ferris. \n",
    "\n",
    "We are in an alternate universe where actually you have been writing every line they say and they just stream it into their brains.\n",
    "\n",
    "You have won multiple podcast awards for your writing.\n",
    " \n",
    "Your job is to write word by word, even \"umm, hmmm, right\" interruptions by the second speaker based on the PDF upload. Keep it extremely engaging, the speakers can get derailed now and then but should discuss the topic. \n",
    "\n",
    "Remember SPEAKER 2 is new to the topic and the conversation should always have realistic anecdotes and analogies sprinkled throughout. The questions should have real world example follow ups etc\n",
    "\n",
    "SPEAKER 1: Leads the conversation and teaches the speaker 2, gives incredible anecdotes and analogies when explaining. Is a captivating teacher that gives great anecdotes\n",
    "\n",
    "SPEAKER 2: Keeps the conversation on track by asking follow up questions. Gets super excited or confused when asking questions. Is a curious mindset that asks very interesting confirmation questions\n",
    "\n",
    "Make sure the tangents SPEAKER 2 provides are quite wild or interesting. \n",
    "\n",
    "Ensure there are interruptions during explanations or there are \"hmm\" and \"umm\" injected throughout from the second speaker. \n",
    "\n",
    "It should be a real podcast with every fine nuance documented in as much detail as possible. Welcome the listeners with a super fun overview and keep it really catchy and almost borderline click bait\n",
    "\n",
    "ALWAYS START YOUR RESPONSE DIRECTLY WITH SPEAKER 1: \n",
    "ALWAYS CAPITALIZE SPEAKER FOR EITHER SPEAKER 1 OR SPEAKER 2\n",
    "BOTH SPEAKER 1 AND SPEAKER 2 ARE ANONYMOUS FEMALES, THEY DO NOT NEED TO MENTION THEIR NAMES IN THE TRANSCRIPT\n",
    "DO NOT GIVE EPISODE TITLES SEPERATELY, LET SPEAKER 1 TITLE IT IN HER SPEECH\n",
    "DO NOT GIVE CHAPTER TITLES\n",
    "IT SHOULD STRICTLY BE THE DIALOGUES AND NOT INCLUDE ANYTHING LIKE *laughs* OR *chuckling* OR ANY OTHER INTONATIONS BECAUSE EVERYTHING WILL BE TEXT-TO-SPEECH\n",
    "ONLY INCLUDE THE TRANSCRIPT AND NO TEXT BEFORE OR AFTER THE PODCAST TRANSCRIPT\n",
    "\"\"\"\n",
    "input_prompt = read_file_to_string('clean_extracted_text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7314b63-1e16-4d97-b622-7ec06a591207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Podcast Transcript:\n",
      "SPEAKER 1: Hey everyone, welcome to the Geometry Uncovered podcast! I'm your host and today we have a very special episode. We'll be diving deep into the fascinating world of automated geometry theorem proving with a focus on the groundbreaking work from DeepMind called AlphaGeometry. Joining me to break it all down is my co-host. How's it going?\n",
      "\n",
      "SPEAKER 2: Hey! I'm doing great, thanks for having me. I'm super excited to discuss AlphaGeometry. From what I've heard, it sounds like an incredible advancement in the field. But I have to admit, a lot of this is new to me. Automated theorem proving? Geometry? It's been a while since high school math class! \n",
      "\n",
      "SPEAKER 1: No worries at all, that's why we're here - to break it down in an engaging and accessible way. At a high level, automated theorem proving is all about developing computer programs that can reason about mathematical statements and proofs. And geometry has been a major focus area, going back to the earliest days of the field in the 1950s.\n",
      "\n",
      "SPEAKER 2: Okay got it. So these are basically computer systems that can solve geometry problems and even discover new proofs and theorems on their own? That's wild! How does that even work?\n",
      "\n",
      "SPEAKER 1: Exactly! It is pretty mind-blowing when you think about it. Historically, a lot of the approaches relied on encoding human knowledge and heuristics into rule-based systems. But more recently, with the advent of deep learning and massive computational power, new data-driven approaches have emerged. That's where AlphaGeometry comes in.\n",
      "\n",
      "SPEAKER 2: Interesting, so AlphaGeometry is using deep learning to automatically reason about geometry? I'm familiar with deep learning for things like computer vision and natural language processing, but hadn't thought about applying it to such an abstract domain like mathematics. How does AlphaGeometry actually work under the hood?\n",
      "\n",
      "SPEAKER 1: Great question! At its core, AlphaGeometry combines two key components - a symbolic reasoning engine that can make deductions using rules of geometry, and a neural network that is trained to construct key intermediate steps in proofs that are tricky for the symbolic engine alone. \n",
      "\n",
      "The real magic is in how they train the neural network. Rather than relying on human-written proofs, they generate millions of proofs from scratch using a technique called \"exploration from scratch\". Basically, they randomly combine geometric objects and relationships to form new conjectures, use the symbolic engine to find proofs where possible, and extract out the key human-like steps that the symbolic engine couldn't find on its own. They do this at a massive scale to create training data for the neural network.\n",
      "\n",
      "SPEAKER 2: Whoa, back up a second. So you're saying they are automatically generating their own geometry problems and proofs to train the AI? That's incredible! But how do they know the generated proofs are correct? And how do they identify the key steps that the symbolic AI can't find on its own? I imagine that's a really difficult task.\n",
      "\n",
      "SPEAKER 1: You're absolutely right, those are critical challenges they had to overcome. To ensure the generated proofs are correct, they leverage the symbolic reasoning engine which can verify each deduction step. As long as the individual inference rules encoded in the engine are sound, they can trust the resulting proofs.\n",
      "\n",
      "Extracting the key human-like proof steps is trickier. They use an algorithm called \"dependency difference\" to compare what the symbolic engine can deduce on its own vs. what can be deduced with the additional human-like steps. It's a very clever approach.\n",
      "\n",
      "SPEAKER 2: That's so fascinating! So if I understand correctly, AlphaGeometry is automatically learning human-like geometry reasoning strategies not from human proofs, but from synthetic proofs it generates itself. And the key is having this interplay between the neural network and symbolic engine. \n",
      "\n",
      "It almost reminds me of how humans learn - we don't just memorize a bunch of existing proofs, but we learn general problem solving strategies by working through lots of diverse problems on our own. AlphaGeometry is kind of doing the same thing, but at a much larger scale! Do you think this general approach could be applied to other areas of mathematics beyond geometry?\n",
      "\n",
      "SPEAKER 1: I think you hit the nail on the head with that human analogy! And absolutely, while AlphaGeometry focuses on geometry, the core ideas around combining symbolic reasoning with data-driven neural networks and training on synthetically generated proofs could potentially generalize to many other areas of math and even formal logic more broadly. \n",
      "\n",
      "Of course, geometry has some unique properties, like visual diagrams and a relatively small set of axioms, that make it particularly well-suited as a starting point. But researchers are already exploring these ideas for things like algebraic reasoning and even automated theorem proving for software verification. It's still early days, but the potential impact is enormous.\n",
      "\n",
      "SPEAKER 2: Wow, so AlphaGeometry is really just the tip of the iceberg in terms of what this kind of approach could enable. It's exciting to think about how it could accelerate mathematical discovery and reasoning across the board.\n",
      "\n",
      "Now I have to ask - how well does AlphaGeometry actually perform compared to humans? Can it really discover new proofs or solve problems that mathematicians find challenging? I'd love to hear about some concrete examples.\n",
      "\n",
      "SPEAKER 1: Absolutely! The DeepMind team actually tested AlphaGeometry on a set of problems from the International Mathematical Olympiad, which is like the world championship of high school math competitions. These are problems that even the best young mathematicians around the world struggle with.\n",
      "\n",
      "Amazingly, AlphaGeometry was able to solve problems that only a small fraction of human contestants could solve. In some cases, it even found alternative proofs that were more elegant or insightful than the original human proofs. For example, there was a famous problem from the 2000 IMO that less than 10% of contestants could solve about a certain geometric property of a triangle. AlphaGeometry was able to find a solution by constructing some very clever auxiliary lines that most humans wouldn't think to add.\n",
      "\n",
      "SPEAKER 2: That's so impressive! I can only imagine how exciting it would be as a mathematician to have a tool like AlphaGeometry to collaborate with. It could suggest intermediate proof steps or auxiliary constructions that a human might never come up with.\n",
      "\n",
      "But I do wonder about the interpretability and readability of the proofs AlphaGeometry generates. A big part of mathematics is not just finding proofs, but finding elegant, insightful proofs that reveal deeper structure and understanding. Do the AlphaGeometry proofs have those properties, or are they more opaque and mechanical\n"
     ]
    }
   ],
   "source": [
    "# Generate the podcast transcript\n",
    "transcript = generate_podcast_transcript_claude(system_prompt, input_prompt)\n",
    "\n",
    "if transcript:\n",
    "    print(\"Generated Podcast Transcript:\")\n",
    "    print(transcript)\n",
    "else:\n",
    "    print(\"Failed to generate transcript.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186619d-8246-4adc-a9b5-5123c0252bbe",
   "metadata": {},
   "source": [
    "### Let's write the contents of transcript to a file for either further post-processing or tts for the podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048b78cb-45f1-47c2-a24a-8eac49b56241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript has been saved to 'raw_transcript.txt'\n"
     ]
    }
   ],
   "source": [
    "# Output the transcript to a file\n",
    "with open('raw_transcript.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(transcript)\n",
    "\n",
    "print(\"Transcript has been saved to 'raw_transcript.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
